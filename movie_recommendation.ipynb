{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c12323c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import sqrt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8718719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config / file paths\n",
    "MOVIES_FILE = \"movies.csv\"\n",
    "RATINGS_FILE = \"ratings.csv\"\n",
    "\n",
    "N_COMPONENTS = 20      # latent factors for NMF\n",
    "RANDOM_STATE = 42\n",
    "TOP_K = 10             # for top-N recommendations / evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43322d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100836 ratings and 9742 movies.\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "def load_data(movies_path=MOVIES_FILE, ratings_path=RATINGS_FILE):\n",
    "    movies = pd.read_csv(movies_path)\n",
    "    ratings = pd.read_csv(ratings_path)\n",
    "    # minimal sanity checks\n",
    "    required_movies_cols = {'movieId', 'title'}\n",
    "    required_ratings_cols = {'userId', 'movieId', 'rating'}\n",
    "    assert required_movies_cols.issubset(movies.columns), \"movies.csv missing required columns\"\n",
    "    assert required_ratings_cols.issubset(ratings.columns), \"ratings.csv missing required columns\"\n",
    "    # ensure types\n",
    "    movies['movieId'] = movies['movieId'].astype(int)\n",
    "    ratings['movieId'] = ratings['movieId'].astype(int)\n",
    "    ratings['userId'] = ratings['userId'].astype(int)\n",
    "    ratings['rating'] = ratings['rating'].astype(float)\n",
    "    return movies, ratings\n",
    "\n",
    "movies, ratings = load_data()\n",
    "\n",
    "print(f\"Loaded {ratings.shape[0]} ratings and {movies.shape[0]} movies.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31b8c07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-item matrix shape: (610, 9724)\n"
     ]
    }
   ],
   "source": [
    "# Build user-item matrix\n",
    "def build_user_item_matrix(ratings_df, fill_value=0.0):\n",
    "    # keep userId and movieId as indexes (ensure compact user/item mapping)\n",
    "    user_ids = ratings_df['userId'].unique()\n",
    "    movie_ids = ratings_df['movieId'].unique()\n",
    "    # But for pivot we prefer continuous index â€” we'll use pivot_table directly\n",
    "    pivot = ratings_df.pivot_table(index='userId', columns='movieId', values='rating', fill_value=fill_value)\n",
    "    return pivot\n",
    "\n",
    "user_item = build_user_item_matrix(ratings)\n",
    "print(f\"User-item matrix shape: {user_item.shape}\")  # (n_users, n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d8de747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping data for movieId->column index and vice versa\n",
    "movie_ids = user_item.columns.tolist()\n",
    "user_ids = user_item.index.tolist()\n",
    "movieid_to_col = {mid: idx for idx, mid in enumerate(movie_ids)}\n",
    "col_to_movieid = {idx: mid for mid, idx in movieid_to_col.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edb70e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained NMF: W shape (users x latent) = (610, 20) H shape (latent x items) = (20, 9724)\n"
     ]
    }
   ],
   "source": [
    "# Train NMF (matrix factorization)\n",
    "def train_nmf(user_item_matrix, n_components=N_COMPONENTS, random_state=RANDOM_STATE):\n",
    "    model = NMF(n_components=n_components, init=\"nndsvda\", random_state=random_state, max_iter=500)\n",
    "    W = model.fit_transform(user_item_matrix.values)   # user x latent\n",
    "    H = model.components_                              # latent x item\n",
    "    return model, W, H\n",
    "\n",
    "nmf_model, W_users, H_items = train_nmf(user_item, n_components=N_COMPONENTS)\n",
    "print(\"Trained NMF: W shape (users x latent) =\", W_users.shape, \"H shape (latent x items) =\", H_items.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6d2dde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted full matrix by multiplication\n",
    "reconstructed = np.dot(W_users, H_items)  # shape: (n_users, n_items)\n",
    "\n",
    "# Wrap reconstructed into DataFrame for easier indexing\n",
    "recon_df = pd.DataFrame(reconstructed, index=user_item.index, columns=user_item.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d81893c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item-item similarity (cosine on item latent factors)\n",
    "item_vectors = H_items.T  # shape (n_items, n_components)\n",
    "item_similarity = cosine_similarity(item_vectors)  # item x item matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6667a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper: top-N similar movies by movieId\n",
    "def similar_movies(movie_id, top_n=10):\n",
    "    if movie_id not in movieid_to_col:\n",
    "        return []\n",
    "    col = movieid_to_col[movie_id]\n",
    "    sims = item_similarity[col]\n",
    "    # sort indices by similarity excluding itself\n",
    "    idx_sorted = np.argsort(-sims)\n",
    "    results = []\n",
    "    count = 0\n",
    "    for idx in idx_sorted:\n",
    "        if idx == col:\n",
    "            continue\n",
    "        results.append((col_to_movieid[idx], sims[idx]))\n",
    "        count += 1\n",
    "        if count >= top_n:\n",
    "            break\n",
    "    # return dataframe with movie titles\n",
    "    rows = []\n",
    "    for mid, score in results:\n",
    "        title = movies.loc[movies['movieId'] == mid, 'title'].values\n",
    "        title = title[0] if len(title) > 0 else str(mid)\n",
    "        rows.append({'movieId': mid, 'title': title, 'similarity': float(score)})\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03db6901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommend for a user\n",
    "def recommend_for_user_nmf(user_id, top_n=10, filter_seen=True):\n",
    "    \"\"\"Recommendations using NMF predicted ratings (recon_df).\"\"\"\n",
    "    if user_id not in recon_df.index:\n",
    "        return []\n",
    "    user_scores = recon_df.loc[user_id]\n",
    "    if filter_seen:\n",
    "        seen = set(user_item.loc[user_id][user_item.loc[user_id] > 0].index.tolist())\n",
    "    else:\n",
    "        seen = set()\n",
    "    # drop seen\n",
    "    candidates = [(mid, user_scores[mid]) for mid in user_scores.index if mid not in seen]\n",
    "    candidates_sorted = sorted(candidates, key=lambda x: -x[1])[:top_n]\n",
    "    rows = []\n",
    "    for mid, score in candidates_sorted:\n",
    "        title = movies.loc[movies['movieId'] == mid, 'title'].values\n",
    "        title = title[0] if len(title) > 0 else str(mid)\n",
    "        rows.append({'movieId': mid, 'title': title, 'predicted_rating': float(score)})\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c74e8f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_for_user_itemcf(user_id, top_n=10, filter_seen=True, k_sim_items=20):\n",
    "    \"\"\"\n",
    "    Item-based: compute score for each unseen item as a weighted sum of user's ratings on similar items.\n",
    "    Use item_similarity matrix computed above.\n",
    "    \"\"\"\n",
    "    if user_id not in user_item.index:\n",
    "        return []\n",
    "    user_row = user_item.loc[user_id]\n",
    "    user_rated = user_row[user_row > 0]\n",
    "    seen = set(user_rated.index.tolist()) if filter_seen else set()\n",
    "    scores = {}\n",
    "    for target_mid in user_item.columns:\n",
    "        if target_mid in seen:\n",
    "            continue\n",
    "        col_idx = movieid_to_col[target_mid]\n",
    "        # find top-k items (by similarity) that this user rated\n",
    "        sim_scores = item_similarity[col_idx]\n",
    "        # take indices of items the user rated\n",
    "        rated_cols = [movieid_to_col[mid] for mid in user_rated.index if mid in movieid_to_col]\n",
    "        # if none rated, skip\n",
    "        if len(rated_cols) == 0:\n",
    "            continue\n",
    "        # compute weighted average\n",
    "        sims = sim_scores[rated_cols]\n",
    "        ratings_by_user = user_rated.values\n",
    "        # pick top-k similar\n",
    "        topk_idx = np.argsort(-sims)[:k_sim_items]\n",
    "        num = np.dot(sims[topk_idx], ratings_by_user[topk_idx])\n",
    "        den = sims[topk_idx].sum()\n",
    "        if den > 0:\n",
    "            scores[target_mid] = num / den\n",
    "    # sort\n",
    "    sorted_items = sorted(scores.items(), key=lambda x: -x[1])[:top_n]\n",
    "    rows = []\n",
    "    for mid, score in sorted_items:\n",
    "        title = movies.loc[movies['movieId'] == mid, 'title'].values\n",
    "        title = title[0] if len(title) > 0 else str(mid)\n",
    "        rows.append({'movieId': mid, 'title': title, 'score': float(score)})\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fb9dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation: RMSE (rating prediction) and Precision@K/Recall@K (top-N)\n",
    "def leave_one_out_split(ratings_df, random_state=RANDOM_STATE):\n",
    "    # keep one rating per user as test; the rest as training\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    train_list = []\n",
    "    test_rows = []\n",
    "    grouped = ratings_df.groupby('userId')\n",
    "    for uid, group in grouped:\n",
    "        if len(group) == 1:\n",
    "            # single rating -> keep in train (can't test)\n",
    "            train_list.append(group)\n",
    "        else:\n",
    "            # choose one index for test\n",
    "            test_idx = rng.choice(group.index)\n",
    "            test_rows.append(ratings_df.loc[test_idx])\n",
    "            train_list.append(group.drop(test_idx))\n",
    "    train_df = pd.concat(train_list).reset_index(drop=True)\n",
    "    test_df = pd.DataFrame(test_rows).reset_index(drop=True)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9a04ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_loocv_nmf(ratings_df, movies_df, n_components=N_COMPONENTS, top_k=TOP_K):\n",
    "    # split\n",
    "    train_df, test_df = leave_one_out_split(ratings_df)\n",
    "    # rebuild user-item train matrix\n",
    "    train_matrix = train_df.pivot_table(index='userId', columns='movieId', values='rating', fill_value=0)\n",
    "    # Keep consistent movie set: use columns from train_matrix\n",
    "    # train NMF\n",
    "    nmf = NMF(n_components=n_components, init=\"nndsvda\", random_state=RANDOM_STATE, max_iter=500)\n",
    "    W = nmf.fit_transform(train_matrix.values)\n",
    "    H = nmf.components_\n",
    "    recon = pd.DataFrame(np.dot(W, H), index=train_matrix.index, columns=train_matrix.columns)\n",
    "    # RMSE on test set: predicted rating for each user/movie pair in test_df (if movie not in train columns, skip)\n",
    "    preds = []\n",
    "    actuals = []\n",
    "    for _, row in test_df.iterrows():\n",
    "        u = row['userId']; m = row['movieId']; r = row['rating']\n",
    "        if (u in recon.index) and (m in recon.columns):\n",
    "            preds.append(recon.loc[u, m])\n",
    "            actuals.append(r)\n",
    "    rmse = sqrt(mean_squared_error(actuals, preds)) if len(preds) > 0 else None\n",
    "\n",
    "    # Precision@K and Recall@K\n",
    "    # Build dictionary of true held-out items per user (single item)\n",
    "    true_per_user = test_df.groupby('userId')['movieId'].apply(list).to_dict()\n",
    "    # For each user in train_matrix, recommend top_k unseen using recon\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    for user in train_matrix.index:\n",
    "        # predicted scores\n",
    "        scores = recon.loc[user]\n",
    "        seen = set(train_matrix.loc[user][train_matrix.loc[user] > 0].index.tolist())\n",
    "        # exclude seen\n",
    "        candidates = [(mid, scores[mid]) for mid in scores.index if mid not in seen]\n",
    "        topn = [mid for mid, _ in sorted(candidates, key=lambda x: -x[1])[:top_k]]\n",
    "        # true item for this user?\n",
    "        true_items = true_per_user.get(user, [])\n",
    "        if len(true_items) == 0:\n",
    "            continue\n",
    "        # compute precision/recall\n",
    "        hit_count = sum(1 for t in true_items if t in topn)\n",
    "        precision = hit_count / top_k\n",
    "        recall = hit_count / len(true_items)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "    prec_at_k = np.mean(precisions) if len(precisions) > 0 else None\n",
    "    rec_at_k = np.mean(recalls) if len(recalls) > 0 else None\n",
    "\n",
    "    return {'rmse': rmse, 'precision@k': prec_at_k, 'recall@k': rec_at_k,\n",
    "            'n_tested_users': len(precisions)}, train_matrix, recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b64c316b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample movie: Toy Story (1995)\n",
      "Top-5 similar movies (by item latent cosine similarity):\n",
      " movieId                                      title  similarity\n",
      "     586                          Home Alone (1990)    0.935984\n",
      "     588                             Aladdin (1992)    0.931915\n",
      "     364                      Lion King, The (1994)    0.922595\n",
      "     500                      Mrs. Doubtfire (1993)    0.904011\n",
      "    1073 Willy Wonka & the Chocolate Factory (1971)    0.901112\n",
      "\n",
      "Top-10 recommendations for user 1 (NMF):\n",
      " movieId                                  title  predicted_rating\n",
      "     589      Terminator 2: Judgment Day (1991)          4.200622\n",
      "    1200                          Aliens (1986)          4.165126\n",
      "    1374 Star Trek II: The Wrath of Khan (1982)          3.372247\n",
      "    1259                     Stand by Me (1986)          3.297137\n",
      "    2762                Sixth Sense, The (1999)          3.232492\n",
      "    1036                        Die Hard (1988)          3.175928\n",
      "    1968             Breakfast Club, The (1985)          2.992686\n",
      "    1356        Star Trek: First Contact (1996)          2.974037\n",
      "     858                  Godfather, The (1972)          2.807578\n",
      "    1376   Star Trek IV: The Voyage Home (1986)          2.725053\n",
      "\n",
      "Top-10 recommendations for user 1 (item-based CF):\n",
      " movieId                                                           title    score\n",
      "    7438                                        Kill Bill: Vol. 2 (2004) 4.904459\n",
      "    5782                     Professional, The (Le professionnel) (1981) 4.900206\n",
      "   92494                                     Dylan Moran: Monster (2004) 4.900012\n",
      "  102217                                  Bill Hicks: Revelations (1993) 4.900012\n",
      "    8024                                   Thing Called Love, The (1993) 4.898158\n",
      "    2762                                         Sixth Sense, The (1999) 4.893408\n",
      "   67255 Girl with the Dragon Tattoo, The (MÃ¤n som hatar kvinnor) (2009) 4.859718\n",
      "    4878                                             Donnie Darko (2001) 4.856322\n",
      "   48738                               Last King of Scotland, The (2006) 4.855246\n",
      "     757                         Ashes of Time (Dung che sai duk) (1994) 4.852219\n",
      "\n",
      "Evaluating NMF with leave-one-out (this can take a minute)...\n",
      "Evaluation results (NMF LOOCV): {'rmse': 3.144129168034223, 'precision@k': np.float64(0.01557377049180328), 'recall@k': np.float64(0.1557377049180328), 'n_tested_users': 610}\n",
      "\n",
      "Saved sample_recommendations_user_1.csv\n"
     ]
    }
   ],
   "source": [
    "# Example usage & small demo\n",
    "if __name__ == \"__main__\":\n",
    "    # Example: show similar movies to a sample movie (choose first movie in movies list)\n",
    "    sample_mid = movies['movieId'].iloc[0]\n",
    "    print(\"\\nSample movie:\", movies.loc[movies['movieId'] == sample_mid, 'title'].values[0])\n",
    "    print(\"Top-5 similar movies (by item latent cosine similarity):\")\n",
    "    print(similar_movies(sample_mid, top_n=5).to_string(index=False))\n",
    "\n",
    "    # Example: recommend for a sample user (pick a user from the dataset)\n",
    "    sample_user = user_item.index[0]\n",
    "    print(f\"\\nTop-10 recommendations for user {sample_user} (NMF):\")\n",
    "    print(recommend_for_user_nmf(sample_user, top_n=10).to_string(index=False))\n",
    "\n",
    "    print(f\"\\nTop-10 recommendations for user {sample_user} (item-based CF):\")\n",
    "    print(recommend_for_user_itemcf(sample_user, top_n=10).to_string(index=False))\n",
    "\n",
    "    # Evaluate with leave-one-out (this may take a bit of time depending on dataset size)\n",
    "    print(\"\\nEvaluating NMF with leave-one-out (this can take a minute)...\")\n",
    "    metrics, train_matrix, recon = evaluate_loocv_nmf(ratings, movies, n_components=N_COMPONENTS, top_k=TOP_K)\n",
    "    print(\"Evaluation results (NMF LOOCV):\", metrics)\n",
    "\n",
    "    # Save / export: top recommendations for a user to CSV (example)\n",
    "    rec_df = recommend_for_user_nmf(sample_user, top_n=20)\n",
    "    rec_df.to_csv(\"sample_recommendations_user_{}.csv\".format(sample_user), index=False)\n",
    "    print(\"\\nSaved sample_recommendations_user_{}.csv\".format(sample_user))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
